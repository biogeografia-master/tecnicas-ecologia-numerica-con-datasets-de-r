---
title: "Técnicas de ecología numérica con *datasets* de R"
author: "Biogeografía (GEO-131)"
date: "`r format(Sys.Date(), '%Y-%m-%d')`"
output:
  # bookdown::github_document2:
  #   number_sections: false
  #   fig_caption: yes
  #   toc: true
  #   toc_depth: 4
  bookdown::html_document2:
    number_sections: false
    code_folding: hide
    fig_caption: yes
    md_extensions: "-fancy_lists"
    css: estilos.css
    toc: true
    toc_depth: 4
editor_options: 
  chunk_output_type: console
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, comment = "#>")
set.seed(123)
# Paquetes base de tu cuaderno + SDM opcional (protegido)
pkg_needed <- c("vegan", "cluster", "indicspecies", "adespatial",
                "sp", "raster", "dismo", "iNEXT", "SpadeR", "ggplot2", "devtools")
has_pkg <- sapply(pkg_needed, function(p) requireNamespace(p, quietly = TRUE))
if (!all(has_pkg)) {
  message("Paquetes no críticos ausentes (se omitirán bloques opcionales): ",
          paste(names(has_pkg)[!has_pkg], collapse=", "))
}
# Podemos cargar múltiples paquetes, así:
sapply(pkg_needed, function(x) library(x, character.only = T))
```

# Fecha/hora de entrega

**Ver portal de la asignatura**



# Introducción

Este cuaderno reúne **17 ejercicios prácticos** para explorar, con datos reales de R, un conjunto de **técnicas fundamentales de ecología numérica y biogeografía**: desde el **análisis exploratorio de datos (AED)** y las **medidas de diversidad** (alfa, beta), pasando por **ordenaciones** (PCA, CA, NMDS, CCA, db-RDA), **agrupamientos** y **pruebas permutacionales**, hasta **modelos de distribución de especies (SDM)** y **estimadores modernos de riqueza** (Chao, iNEXT). El hilo conductor es doble: (i) **formular preguntas ecológico-biogeográficas claras** y (ii) **elegir y aplicar** la técnica apropiada con sus **supuestos, limitaciones e interpretación**.

Todos los ejercicios usan *datasets* clásicos (p. ej., `dune`, `varespec/varechem`, `BCI`, `mite`), lo que facilita contrastar resultados con la literatura y con ayuda de IA (siempre **verificando** contra la documentación del paquete; por ejemplo, consulta `?dune`). Cada actividad termina con un **mandato de interpretación**, **formulación de preguntas** y **reflexión** sobre **implicaciones ecológicas, biogeográficas y, cuando proceda, de conservación**. Más que “correr código”, el objetivo es **razonar**: qué mide cada índice, qué representa cada eje, qué hipótesis subyacen a cada método, y cómo influyen **transformaciones**, **distancias**, **diseño de muestreo** y **escala espacial** en las conclusiones.

El cuaderno está diseñado para **ejecución reproducible** (semillas fijadas, bloques autocontenidos) y para que puedas **elegir 1 de 17** según tus intereses: comparar **modo Q vs. R**, estimar la **riqueza esperada** con **Chao/iNEXT**, descomponer la **beta-diversidad** en **recambio** y **anidamiento**, o construir un **SDM** introductorio con regresión logística como alternativa ligera a MaxEnt/ML. En todos los casos se prioriza la **interpretación crítica** por encima de la longitud del código.

# Objetivos

1. **Vincular preguntas ecológico-biogeográficas con herramientas cuantitativas**, eligiendo medidas de **distancia**, **transformaciones** y **técnicas** acordes a los datos y sus supuestos.

2. **Aplicar e interpretar** técnicas de **ordenación** (PCA, CA, NMDS, CCA, db-RDA/capscale) y **agrupamiento** (UPGMA, Ward), incluyendo **verificación de supuestos** y lectura de **biplots** y **dendrogramas**.

3. **Cuantificar diversidad** (alfa, beta) y **particionarla** para inferir **patrones de composición** y **heterogeneidad** entre sitios.

4. **Estimar riqueza esperada** y **cobertura de muestreo** con **Chao/iNEXT**, interpretando **curvas de rarefacción/extrapolación** y diferencias entre `S_obs` y estimadores (`S_chao1`, `S_chao1_bc`, `S_ichao1`).

5. **Probar hipótesis** sobre diferencias entre grupos o gradientes mediante **PERMANOVA**, **betadisper** y **pruebas permutacionales**, distinguiendo efectos de **centroides** vs. **dispersión**.

6. **Analizar estructura espacial** (superficies de tendencia, **MEM/PCNM**) y **partición de varianza** ambiente–espacio, relacionando **procesos** (filtros ambientales, dispersión limitada) y **escalas**.

7. **Construir un SDM introductorio** (GLM binomial) para generar **mapas de idoneidad**, discutir **evaluación** (p. ej., AUC/ROC), **umbrales** y **riesgos de extrapolación**.

8. **Comunicar resultados**: para cada ejercicio, **interpretar salidas**, **formular al menos dos preguntas** que los resultados permitan abordar y **reflexionar** sobre **implicaciones ecológicas/biogeográficas** y, cuando proceda, **de conservación**.


# Cómo usar estos ejercicios

* Cada **ejercicio** está pensado para realizarse en **60 minutos**, con objetivos, dataset, pasos y preguntas. **Elige uno y anúncialo en el foro**. **IMPORTANTE** Te desaconsejo elegir por longitud de código y texto, pues los ejercicios que tienen menos código, son normalmente los más complicados.

* Las secciones incluyen **código ejecutable** y **tareas** de interpretación. El código ejecutable, lógicamente, debe ejecutarse para comprobar que funciona, y para familiarizarse con la sintaxis.

* Debes investigar, por tu cuenta y con ayuda de IA, sobre lo siguiente:
  - **Los *datasets* usados, para entender su origen, muestreo, y variables medidas.** Esto es muy importante, porque si no comprendes los datos, muchas preguntas no podrás responderlas. Puedes preguntar a IAs sobre los *datasets*, pues la mayoría son conocidos; eso sí, no aceptes descripciones de la IA sin comprobarlas. Dado que todos los *datasets* usados en estos ejercicios vienen asociados a paquetes de R,  también puedes ver sus correspondientes descripciones usando la consola; por ejemplo, para ver la descripción del *dataset* `dune`, basta con ejecutar `help(dune)` o `?dune` en la consola de R.
  - **Discute limitaciones de los datasets y decisiones analíticas (transformaciones, distancias, métodos).
  - **Las técnicas empleadas en cada caso, para explicar qué responden, para qué sirven, y sus supuestos.** Investigando para qué sirve la técnica usada en tu ejercicio elegido, podrás detemrinar qué preguntas te ayuda a responder dicha técnica. Investigando sobre los supuestos, sabrás cuándo tus datos cumplen con las condiciones para usar una técnica u otra.

---

# Ejercicio 01 · EDA + diversidad + clúster (dune)

**Objetivo.** Reforzar AED, diversidad alfa/beta y agrupamiento jerárquico (UPGMA) con `dune` (comunidades de plantas) y `dune.env` (ambiente).

**Dataset.**

```{r}
library(vegan)
data(dune); data(dune.env)
dim(dune); dim(dune.env)
head(dune[,1:6]); head(dune.env)
```

**Pasos.**

1. **EDA** de variables ambientales:

```{r}
summary(dune.env)
table(dune.env$Management)
boxplot(A1 ~ Moisture, data=dune.env, main="A1 por humedad")
boxplot(A1 ~ Management, data=dune.env, main="A1 por Manejo")
```

2. **Diversidad alfa** (Shannon/Simpson) y **riqueza** por sitio:

```{r}
div_sh <- diversity(dune, "shannon")
div_si <- diversity(dune, "simpson")
rich   <- specnumber(dune)
plot(div_sh, type="h", main="Shannon por sitio", xlab="Sitio", ylab="H'")
```

3. **Distancias Bray–Curtis** y **clúster UPGMA** (average):

```{r}
d_bc <- vegdist(dune, method="bray")
clu  <- hclust(d_bc, method="average")
plot(clu, main="Dendrograma (Bray–Curtis + UPGMA)")
```

**Mandato**

0. **Preguntas guía para responder.** ¿Cuántos grupos cortarías? ¿Se asocian con `Management`, `Moisture` o `A1`?

1. **Interpreta**: explica qué te dicen los grupos sobre la composición y cómo se relacionan (o no) con `Management`/`A1`.

2. **Formula dos preguntas** que puedan responderse con estos resultados o con la técnica empleada (p. ej., ¿qué especies definen cada grupo?, ¿hay gradientes ambientales subyacentes?).

3. **Reflexiona** sobre implicaciones **ecológicas/biogeográficas** y, si aplica, **de conservación** (p. ej., manejo diferenciado por grupos).

---

# Ejercicio 02 · Modos Q/R y paradoja de Orlóci

**Objetivo.** Comparar **modo Q** (sitios) vs **modo R** (variables), y mostrar cómo **transformaciones** y **medidas** cambian conclusiones (paradoja de Orlóci).

```{r}
data(varespec); data(varechem)
# Modo Q: distancias entre sitios con abundancias crudas vs Hellinger
d_raw <- vegdist(varespec, "bray")
sp_hel <- decostand(varespec, "hellinger")
d_hel <- dist(sp_hel)  # euclídea sobre Hellinger
par(mfrow=c(1,2)); plot(hclust(d_raw), main="Clúster (Bray, crudo)")
plot(hclust(d_hel), main="Clúster (Euclídea, Hellinger)"); par(mfrow=c(1,1))
```

```{r}
# Modo R: correlaciones entre variables ambientales
cor_mat <- cor(varechem)
round(cor_mat, 2)
```

**Mandato**

0. **Describe diferencias entre dendrogramas y justifica elección** de transformación/distancia.**

1. **Interpreta** las discrepancias entre modos Q/R y su causa.

2. **Formula dos preguntas** que puedan responderse con estos resultados o con la técnica empleada (p. ej., ¿qué transformación estabiliza mejor la varianza?, ¿qué variables redundantes detecta el modo R?).

3. **Reflexiona** sobre implicaciones para comparar sitios y para el diseño de muestreo/variables.

---

# Ejercicio 03 · NMDS + envfit (dune)

**Objetivo.** Realizar **NMDS** (Bray) y ajustar vectores ambientales (`envfit`).

```{r}
set.seed(123)
m <- metaMDS(dune, distance="bray", k=2, trymax=50)
m$stress
plot(m, type="t", main=paste("NMDS (stress =", round(m$stress,3),")"))
ef <- envfit(m ~ A1 + Moisture + Management, data = dune.env, permutations=999)
ef
plot(ef, col="red")
```

**Mandato**

0. **Preguntas guía para responder.** ¿Qué variables se alinean con el gradiente principal? ¿Cómo interpretar signos y longitudes de flechas?

1. **Interpreta** el diagrama (orientaciones, longitudes, stress).

2. **Formula dos preguntas** que puedan responderse con estos resultados o con la técnica empleada (p. ej., ¿qué pasa si excluimos una variable?, ¿coinciden clusters de Ejercicio 01 con ejes NMDS?).

3. **Reflexiona** sobre gradientes ambientales y decisiones de manejo.

---

# Ejercicio 04 · PCA vs CA (varechem/varespec)

**Objetivo.** Comparar **PCA** sobre ambiente (escalado) y **CA** sobre especies.

```{r}
# PCA en ambiente
pca_env <- rda(scale(varechem))
plot(pca_env, main="PCA de variables ambientales (escaladas)")
# CA en especies (adecuado para conteos/distribuciones sesgadas)
ca_sp <- cca(varespec)  # CA clásica
plot(ca_sp, main="CA de comunidades (varespec)")
```

**Mandato**

0. **Contrasta supuestos de PCA (lineal) vs CA (chi-cuadrado) y cuándo usar cada uno**.

1. **Interpreta** ambos biplots y sus supuestos.

2. **Formula dos preguntas** que puedan responderse con estos resultados o con la técnica empleada (p. ej., ¿qué especies/variables dominan cada eje?, ¿cómo cambian resultados con estandarización diferente?).

3. **Reflexiona** sobre elección de técnica según la pregunta biogeográfica.

---

# Ejercicio 05 · RDA (Hellinger) y varianza explicada

**Objetivo.** Modelar composición (Hellinger) con RDA y cuantificar varianza explicada.

```{r}
Y <- decostand(varespec, "hellinger")
rda_mod <- rda(Y ~ Al + P + K + pH, data=varechem)
summary(rda_mod)
anova(rda_mod, permutations=999)
Rsq <- RsquareAdj(rda_mod); Rsq
plot(rda_mod, main="RDA (Hellinger) ~ Al + P + K + pH")
```

**Mandato**

0. **Preguntas guía para responder.** ¿Cuánta varianza ajustada explica el modelo? ¿Qué variables son más importantes?

1. **Interpreta** coeficientes/cargas y $R^2_{aj}$.

2. **Dos preguntas** (p. ej., ¿qué ocurre si colinealidad?, ¿qué variables añadir/quitar?).

3. **Reflexiona** sobre mecanismos ambientales que estructuran comunidades.

---

# Ejercicio 06 · Partición de varianza ambiente vs espacio (mite)

**Objetivo.** Separar efectos **ambientales** y **espaciales** usando `varpart` con coordenadas polinomiales (superficies de tendencia).

```{r}
data(mite); data(mite.env); data(mite.xy)
Y <- decostand(mite, "hellinger")
# Polinomios espaciales (x, y, x^2, y^2, xy)
S <- with(mite.xy, data.frame(x, y, x2 = x^2, y2 = y^2, xy = x*y))
vpart <- varpart(Y, mite.env[,c("SubsDens","WatrCont","Substrate")], S)
vpart
plot(vpart, bg=c("steelblue","orange"), Xnames=c("Ambiente","Espacio"))
```

**Mandato**

0. Interpreta los **componentes**: solo ambiente, solo espacio, compartido, residuo.

1. **Interpreta** la fracción compartida (espacio–ambiente).

2. **Formula dos preguntas** que puedan responderse con estos resultados o con la técnica empleada (p. ej., ¿hay dispersión limitada?, ¿qué escala espacial falta?).

3. **Reflexiona** sobre procesos ecológicos y planes de muestreo espacial.

---

# Ejercicio 07 · PERMANOVA + betadisper (dune)

**Objetivo.** Probar diferencias de **composición** entre niveles de `Management` y verificar **homogeneidad de dispersión**.

```{r}
d <- vegdist(dune, "bray")
adon <- adonis2(d ~ Management, data=dune.env, permutations=999)
adon
bd <- betadisper(d, group = dune.env$Management)
anova(bd); permutest(bd)
plot(bd, main="Dispersión multivariante por manejo")
```

**Mandato**

0. **Preguntas guía para responder.** ¿Las diferencias entre grupos son por **centroides** (composición) o por **dispersión** (heterogeneidad)?

1. **Interpreta** `adonis2` y `betadisper` conjuntamente.

2. **Formula dos preguntas** que puedan responderse con estos resultados o con la técnica empleada (p. ej., ¿hay pseudo-replicación?, ¿deberíamos estratificar permutaciones?).

3. **Reflexiona** sobre decisiones de manejo basadas en composición/dispersión.

---

# Ejercicio 08 · Especies indicadoras

**Objetivo.** Identificar **especies indicadoras** de grupos de sitios.

```{r, results='asis'}
ok_ind <- requireNamespace("indicspecies", quietly = TRUE)
if (ok_ind) {
  library(indicspecies)
  d_br <- vegdist(dune, "bray")
  gr <- cutree(hclust(d_br, "average"), k = 3)
  iv <- multipatt(dune, gr, func="IndVal.g", control = how(nperm=499))
  print(summary(iv, indvalcomp=TRUE, alpha=0.05))
} else {
  cat("**Paquete 'indicspecies' no instalado.** Interprete grupos del Ejercicio 01 y discuta posibles indicadoras.")
}
```

**Mandato**

0. **Reporta especies indicadoras (valor de $p$).**

1. **Interpreta** significancia y valor indicador.

2. **Formula dos preguntas** que puedan responderse con estos resultados o con la técnica empleada (p. ej., ¿indicadoras cambian con k?, ¿estabilidad temporal?).

3. **Reflexiona** sobre bioindicación y conservación de hábitats clave.

---

# Ejercicio 09 · Acumulación y rarefacción (BCI)

**Objetivo.** Evaluar riqueza con **curvas de acumulación** y **rarefacción**.

```{r}
data(BCI)  # 50 ha, conteos por especie en parcelas
spec_acc <- specaccum(BCI, method="random")
plot(spec_acc, ci.type="poly", col="blue", lwd=2, ci.lty=0, ci.col=adjustcolor("lightblue",0.5),
     main="Curva de acumulación de especies (BCI)")
rarecurve(BCI, step=20, sample=min(rowSums(BCI)), col="grey", label=FALSE)
```

**Mandato**

0. **Preguntas guía para responder.** ¿La curva tiende a **saturación**? ¿Qué implica para el muestreo?

1. **Interpreta** forma de la curva y CIs.

2. **Formula dos preguntas** que puedan responderse con estos resultados o con la técnica empleada (p. ej., ¿cuánto esfuerzo adicional lograría *x* especies?, ¿diferencias entre parcelas?).

3. **Reflexiona** sobre planificación de muestreos y costos/beneficios.

---

# Ejercicio 10 · Procrustes: comparar ordenaciones

**Objetivo.** Comparar configuraciones de puntos con **rotación de Procrustes** y prueba `protest`.

```{r}
# Comparar NMDS de especies vs PCoA de ambiente (Gower)
library(vegan)
library(cluster)
data(dune); data(dune.env)

## 1) NMDS en especies (Bray-Curtis)
set.seed(1)
nmds <- metaMDS(dune, distance = "bray", k = 2, trymax = 50)

## 2) Distancia Gower para ambiente (admite factores y numéricas)
Dg <- daisy(dune.env, metric = "gower")

## 3) PCoA (cmdscale) sobre Gower
pcoa <- cmdscale(as.dist(Dg), k = 2, eig = TRUE)

## 4) Procrustes (sitios vs sitios)
X <- scores(nmds, display = "sites")      # coordenadas NMDS
Y <- pcoa$points                          # coordenadas PCoA (ambiente)

pr <- procrustes(X, Y, symmetric = TRUE)
plot(pr, main = "Procrustes: NMDS (especies) vs PCoA Gower (ambiente)")

## 5) PROTEST (prueba de concordancia)
protest(X, Y, permutations = 999)
```

**Mandato**

0. **Interpreta longitudes de segmentos y valor de la prueba**.

1. **Interpreta** ajuste global y desajustes puntuales.

2. **Formula dos preguntas** que puedan responderse con estos resultados o con la técnica empleada (p. ej., ¿qué sitios rompen la concordancia?, ¿qué variable ambiental falta?).

3. **Reflexiona** sobre concordancia biota–ambiente en tu sistema de estudio.

---

# Ejercicio 11 · Elegir k con silhouette

**Objetivo.** Seleccionar número de **clústers** con **ancho de silueta**.

```{r}
library(cluster)
d <- vegdist(varespec, "bray")
sil_scores <- sapply(2:8, function(k){
  gr <- cutree(hclust(d, "ward.D2"), k)
  mean(silhouette(gr, d)[, "sil_width"])
})
plot(2:8, sil_scores, type="b", xlab="k", ylab="Ancho medio de silueta")
best_k <- which.max(sil_scores) + 1; best_k
```

**Mandato**

0. **Preguntas guía para responder.** ¿Qué k maximiza la coherencia? Visualiza el dendrograma con ese corte.

1. **Interpreta** el valor máximo y alternativas cercanas.

2. **Formula dos preguntas** que puedan responderse con estos resultados o con la técnica empleada (p. ej., ¿estabilidad de k ante otras distancias?, ¿cambios si estandarizamos?).

3. **Reflexiona** sobre el significado ecológico de los clústers.

---

# Ejercicio 12 · CCA (varespec \~ varechem)

**Objetivo.** Relacionar composición con ambiente con **CCA** (respuesta unimodal).

```{r}
cca_mod <- cca(varespec ~ Al + P + K + pH, data=varechem)
anova(cca_mod); anova(cca_mod, by="term", permutations=999)
plot(cca_mod, main="CCA: varespec ~ Al + P + K + pH")
```

**Mandato**

0. **Pregunta guía para responder.** ¿Qué variables explican ejes canónicos significativos?

1. **Interpreta** la ordenación y significancias por término.

2. **Formula dos preguntas** que puedan responderse con estos resultados o con la técnica empleada (p. ej., ¿existen efectos no lineales?, ¿qué sitios extremos aparecen?).

3. **Reflexiona** sobre gradientes y nichos unimodales.

---

# Ejercicio 13 · db-RDA / capscale (distancia no euclídea)

**Objetivo.** Usar **capscale** (db-RDA) con Bray–Curtis y covariables.

```{r}
db <- capscale(dune ~ Management + Condition(Moisture), data=dune.env, distance="bray")
anova(db); anova(db, by="terms", permutations=999)
plot(db, main="db-RDA: Management | Moisture (Bray)")
```

**Mandato**

0. **Pregunta guía para responder.** ¿Qué aporta condicionar por `Moisture`?

1. **Interpreta** el efecto parcializado de `Management`.

2. **Formula dos preguntas** que puedan responderse con estos resultados o con la técnica empleada (p. ej., ¿qué otras covariables controlar?, ¿cambia la varianza explicada?).

3. **Reflexiona** sobre control de confusores en biogeografía.

---

# Ejercicio 14 · Tendencia espacial (polinomios) vs MEM/PCNM (opcional)

**Objetivo.** Contrastar **superficies de tendencia** con **eigenvectores espaciales** (si está `adespatial`).

```{r, results='asis'}
library(vegan)
data(mite); data(mite.xy)

# Respuesta Hellinger
Y <- as.data.frame(decostand(mite, "hellinger"))

# Asegurar correspondencia 1–a–1 por si antes filtraste algo (opcional)
keep <- complete.cases(mite.xy$x, mite.xy$y)
Y2   <- Y[keep, , drop = FALSE]
xy2  <- mite.xy[keep, , drop = FALSE]

# RDA con polinomios construidos en la fórmula
mod_poly <- rda(Y2 ~ x + y + I(x^2) + I(y^2) + I(x*y), data = xy2)
anova(mod_poly)
cat("Modelo polinómico ajustado.\n")
```

**Mandato**

0. **Compara varianza explicada por tendencia vs MEM.**

1. **Interpreta** la forma espacial capturada por la tendencia.

2. **Formula dos preguntas** que puedan responderse con estos resultados o con la técnica empleada (p. ej., ¿qué escalas detectan MEM adicionales?, ¿hay borde/anisotropía?).

3. **Reflexiona** sobre procesos espaciales y dispersión.

---

# Ejercicio 15 · Diversidad beta (índices y partición)

**Objetivo.** Calcular **beta-diversidad** con distintos índices y discutir su **partición** en componentes de recambio y anidamiento.

```{r}
library(vegan)
library(betapart)

# Datos de ejemplo
data(varespec)

# Matriz de presencia-ausencia
va_pa <- decostand(varespec, "pa")

# ---- Índices de disimilitud ----
d_jac <- vegdist(va_pa, "jaccard")                     # Jaccard
d_sor <- vegdist(va_pa, method="bray", binary=TRUE)    # Sørensen binario
d_bray <- vegdist(varespec, "bray")                    # Bray-Curtis (abundancias)

bd <- betadiver(va_pa, method="w")  # Whittaker (gamma/alpha - 1)

summary(as.vector(d_jac))
summary(as.vector(d_bray))

hist(as.vector(d_jac), 
     main="Distribución de disimilitudes Jaccard", 
     xlab="d_J")

# ---- Partición: turnover vs nestedness ----
bp <- betapart.core(va_pa)
bp_sor <- beta.pair(bp)   # Sørensen → turnover + nestedness
bp_jac <- beta.pair(bp, index.family="jaccard")

bp_sor$beta.sor  # disimilitud total
bp_sor$beta.sim  # recambio (turnover)
bp_sor$beta.sne  # anidamiento

# ---- Contribuciones locales (opcional, requiere adespatial) ----
if (requireNamespace("adespatial", quietly = TRUE)) {
  library(adespatial)
  bd_lcbd <- beta.div(va_pa, method="jaccard", sqrt.D=TRUE, nperm=999)
  bd_lcbd$LCBD[1:10]   # primeras contribuciones locales
}
```

---

**Mandato**

0. **Explica** cuándo preferir índices asimétricos (ignoran dobles ceros) y cómo cambia la historia con abundancias vs. presencia-ausencia.

1. **Interpreta** las distribuciones de disimilitud y su rango.

2. **Compara** la proporción de recambio vs. anidamiento en los resultados de la partición (ej. Sørensen → `beta.sim` vs. `beta.sne`).

3. **Formula dos preguntas** que puedan responderse con estos resultados o con la técnica empleada (ej.: ¿qué contribución hace cada sitio a β?, ¿predomina recambio o anidamiento?).

4. **Reflexiona** sobre conectividad y manejo a escala de paisaje.

---

# Ejercicio 16 · Diversidad alfa con estimadores de Chao (SpadeR, iNEXT)

**Objetivo.** Estimar índices de diversidad, estimar y comparar **riqueza observada** y **riqueza esperada (Chao)**, y construir **curvas de rarefacción/extrapolación** usando **SpadeR** e **iNEXT** con el dataset **BCI**. Se muestra también cómo invocar la función `estimacion_riqueza_chao` desde tu repositorio (opcional).

```{r}
# Paquetes necesarios (bloques opcionales protegidos)
ok_vegan  <- requireNamespace("vegan",  quietly = TRUE)
ok_iNEXT  <- requireNamespace("iNEXT",  quietly = TRUE)
ok_SpadeR <- requireNamespace("SpadeR", quietly = TRUE)
ok_ggplot <- requireNamespace("ggplot2", quietly = TRUE)
ok_devtools <- requireNamespace("devtools", quietly = TRUE)

if (!ok_vegan) stop("Instala 'vegan' para usar BCI.")

library(vegan)
data(BCI)             # Matriz: 50 parcelas x especies (abundancias)

# 1) Métricas alfa básicas por parcela (vegan): Riqueza, Shannon, Hill números
rich <- specnumber(BCI)                 # N0
H    <- diversity(BCI, index = "shannon")
N1   <- exp(H)                          # Hill q=1
N2   <- diversity(BCI, index = "inv")   # Inverso de Simpson (Hill q=2)

alpha_tab <- data.frame(
  Parcela = seq_len(nrow(BCI)),
  Riqueza_obs = rich,
  Shannon = H,
  Hill1 = N1,
  Hill2 = N2
)
head(alpha_tab, 10)
```

El gráfico y tabla a continuación muestran, de forma consolidada en una única tabla y gráfico, un resumen de estimación de riqueza por parcelas de PCI.

```{r}
# 2) Selección de un subconjunto de parcelas para curvas iNEXT (para gráficos legibles)
set.seed(123)
sel <- c(1, 10, 20, 30, 40)  # Fijo para reproducibilidad

# 3) Curvas de rarefacción/extrapolación e índices de Chao (opcional si están iNEXT/SpadeR)
if (ok_iNEXT && ok_SpadeR && ok_ggplot) {
  library(iNEXT); library(SpadeR); library(ggplot2)

  # Preparar objeto de ensamblajes para iNEXT: lista de vectores de abundancias
  ensamblajes <- lapply(sel, function(i) as.numeric(BCI[i, ]))
  names(ensamblajes) <- paste0("P", sel)

  # iNEXT para riqueza (q=0)
  out_inext <- iNEXT(ensamblajes, q = 0, datatype = "abundance", knots = 200)
  print(ggiNEXT(out_inext, type = 1) + theme_bw() +
          labs(x = "Número de individuos", y = "Riqueza de especies",
               title = "Curvas de rarefacción / extrapolación (iNEXT)"))

  # Estimadores de riqueza de Chao para el conjunto total y para el subconjunto
  chao_total <- SpadeR::ChaoSpecies(colSums(BCI), datatype = "abundance", conf = 0.95)
  chao_total_sp_df <- as.data.frame(chao_total$Species_table)
  chao_sel   <- lapply(ensamblajes, function(v) SpadeR::ChaoSpecies(v, datatype = "abundance", conf = 0.95))
  chao_sel_sp_df   <- lapply(chao_sel, function(v) as.data.frame(v$Species_table))

  chao_df <- data.frame(
    Unidad  = c("BCI_total", names(chao_sel)),
    S_obs   = c(
      with(chao_total$Basic_data_information, as.numeric(Value[Variable=='D'])),
      as.vector(sapply(
        chao_sel,
        function(z)
          as.numeric(with(z$Basic_data_information, Value[Variable=='D']))))),
    S_chao1   = c(
      chao_total_sp_df[
        grep('Chao1 \\(Chao, 1984\\)', rownames(chao_total_sp_df)),
        grep('Estimate', colnames(chao_total_sp_df))],
      as.vector(sapply(chao_sel_sp_df, function(z) z[
        grep('Chao1 \\(Chao, 1984\\)', rownames(z)),
        grep('Estimate', colnames(z))]))),
    S_chao1_bc   = c(
      chao_total_sp_df[
        grep('Chao1-bc', rownames(chao_total_sp_df)),
        grep('Estimate', colnames(chao_total_sp_df))],
      as.vector(sapply(chao_sel_sp_df, function(z) z[
        grep('Chao1-bc', rownames(z)),
        grep('Estimate', colnames(z))]))),
    S_ichao1   = c(
      chao_total_sp_df[
        grep('iChao1 \\(Chiu et al. 2014\\)', rownames(chao_total_sp_df)),
        grep('Estimate', colnames(chao_total_sp_df))],
      as.vector(sapply(chao_sel_sp_df, function(z) z[
        grep('iChao1 \\(Chiu et al. 2014\\)', rownames(z)),
        grep('Estimate', colnames(z))])))
  )
  chao_df
} else {
  message("**Parte iNEXT/SpadeR omitida** (faltan paquetes 'iNEXT' y/o 'SpadeR' y/o 'ggplot2').\n",
          "Aún puedes usar la tabla 'alpha_tab' con métricas alfa básicas (vegan).")
}
```

Los gráficos y tablas a continuación muestran el detalle del resumen de estimación de riqueza anterior, pero parcela a parcela.

```{r}
# 4) Cargar funciones y usar 'estimacion_riqueza_chao'
source('R/funciones.R')
if (exists("estimacion_riqueza_chao") && ok_iNEXT && ok_SpadeR) {
  res_est <- sapply(
    names(ensamblajes) <- paste0("P", sel),
    function(x)
      estimacion_riqueza_chao(mc = colSums(BCI[as.numeric(gsub('P', '', x)), ])),
    simplify = FALSE
  )
  # Gráfico iNEXT con paleta (devuelve ggplot2)
  res_est
} else {
  message("Funciones cargadas pero faltan 'iNEXT'/'SpadeR', o no se encontró 'estimacion_riqueza_chao'.")
}
```

**Mandato**

0. **Compara** la **riqueza observada** (`S_obs`) con la **riqueza esperada** (`S_chao1`, `S_chao1_bc`, `S_ichao1`) y con las **curvas iNEXT**: ¿coinciden las tendencias? ¿qué tan lejos está la asintota de la muestra actual?

1. **Interpreta**: explica la **forma** de las curvas (rarefacción vs extrapolación), la **cobertura de muestreo** implícita y el **signo/magnitud** de las diferencias entre `S_obs` y `S_chao1` en el conjunto total y en las parcelas seleccionadas.

2. **Formula dos preguntas** que puedan responderse con estos resultados o con la técnica empleada (p. ej., *¿qué esfuerzo adicional de muestreo se requiere para alcanzar el 95% de la riqueza esperada?*; *¿qué parcelas muestran mayor submuestreo relativo y por qué?*).

3. **Reflexiona** sobre **implicaciones ecológicas/biogeográficas** (p. ej., dominancia/raras, heterogeneidad espacial del ensamblaje) y, si aplica, de **conservación** (p. ej., priorización de parcelas con alta riqueza estimada no muestreada, planificación de esfuerzo).

---

# Ejercicio 17 · SDM (Modelos de Distribución de Especies) — *introducción compacta*

**Objetivo.** Construir un **SDM simple** con regresión logística (presencia/ausencia) y variables ambientales para generar un **mapa de idoneidad**. Alternativa ligera a MaxEnt/ML para aula. *(Bloque protegido: se omite si faltan paquetes espaciales.)*

**Datos.** Usamos `meuse` (paquete `sp`) como “paisaje” con dos variables (zinc, cobre). Simulamos presencias de una “especie” asociada a bajo Zn (solo para el ejercicio), ajustamos un **GLM binomial** y proyectamos.

```{r, results='asis'}
if (requireNamespace("sp", quietly=TRUE) &&
    requireNamespace("raster", quietly=TRUE) &&
    requireNamespace("dismo", quietly=TRUE)) {

  library(sp); library(raster); library(dismo)

  data(meuse)                # datos puntuales con x, y y varias variables
  coordinates(meuse) <- ~x+y # convertir a objeto espacial
  meuse_df <- as.data.frame(meuse)

  # 1) Simular presencia (1) si zinc está por debajo de la mediana (asociación negativa)
  meuse_df$pres <- as.integer(meuse_df$zinc < median(meuse_df$zinc))

  # 2) Preparar raster ambiental (interpolación rápida por IDW a fines docentes)
  #    Creamos rejilla y hacemos IDW simple con 'dismo::interpolate' usando modelos de 'gstat'
  #    Para brevedad, rasterizamos por kriging simple incorporado en 'dismo::gmap' no es necesario; usamos 'rasterFromXYZ'.
  #    Aquí generamos una cuadrícula a partir de los puntos (resolución gruesa para rapidez):
  rngx <- range(meuse_df$x); rngy <- range(meuse_df$y)
  r <- raster(xmn=rngx[1], xmx=rngx[2], ymn=rngy[1], ymx=rngy[2], res=50)

  # Rasterizar por promedio de celdas (simple y suficiente para demostración):
  r_zinc  <- rasterize(meuse_df[,c("x","y")], r, meuse_df$zinc, fun=mean)
  r_copper<- rasterize(meuse_df[,c("x","y")], r, meuse_df$copper, fun=mean)

  env_stack <- stack(r_zinc, r_copper)
  names(env_stack) <- c("zinc","copper")

  # 3) Ajustar SDM (GLM binomial)
  mod <- glm(pres ~ zinc + copper, data = meuse_df, family = binomial)
  summ <- capture.output(summary(mod)); cat(paste(summ, collapse="\n"), "\n")

  # 4) Predecir idoneidad (probabilidad de presencia)
  pred <- predict(env_stack, mod, type="response")
  plot(pred, main="SDM (GLM): Probabilidad de presencia")
  points(meuse_df$x, meuse_df$y, pch=19,
         col=ifelse(meuse_df$pres==1, "red", "blue"))
  legend("topleft", legend=c("Presencia (simulada)","Ausencia"),
         pch=19, col=c("red","blue"), bty="n")

  # 5) Evaluación rápida (holdout simple 70/30):
  set.seed(123)
  idx <- sample.int(nrow(meuse_df), size = floor(0.7*nrow(meuse_df)))
  fit <- glm(pres ~ zinc + copper, data = meuse_df[idx,], family=binomial)
  prd <- predict(fit, newdata = meuse_df[-idx,], type="response")
  lab <- meuse_df$pres[-idx]
  # Curva ROC/AUC básica (dismo::evaluate)
  ev  <- evaluate(p = prd[lab==1], a = prd[lab==0])
  print(ev)
  plot(ev, 'ROC', main = sprintf("ROC (AUC = %.3f)", as.numeric(ev@auc)))
} else {
  cat("**Paquetes espaciales no instalados ('sp','raster','dismo'): SDM omitido.**\n",
      "Instale estos paquetes para ejecutar este ejercicio.\n")
}
```

**Sugerencias de extensión (si hay tiempo/recursos).**

* Probar términos no lineales (p. ej., `poly(zinc,2)`).
* Comparar con un **modelo de fondo** (pseudo-ausencias) si solo se dispone de presencias.
* Si cuentan con `maxent.jar`, explorar `dismo::maxent` con el mismo stack ambiental.

**Mandato final.**

1. **Interpreta** el mapa de idoneidad y los coeficientes del GLM (signo, magnitud, significancia).

2. **Formula dos preguntas** que puedan responderse con estos resultados o con la técnica empleada (p. ej., ¿qué umbral usarías para convertir probabilidad en presencia?, ¿qué variable añadirías para mejorar el AUC?).

3. **Reflexiona** sobre implicaciones **ecológicas/biogeográficas** (idoneidad, nicho, extrapolación) y **de conservación** (priorización espacial, muestreo dirigido, riesgos de sobreajuste).

---


```{r}
sessionInfo()
```
